{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b77ab789-6733-4045-a202-30c8a3f6a91e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"rm.txt\") as f:\n",
    "    a = [i.split(\" @\")[0].replace(\"\\n\", \"\") for i in f.readlines()]\n",
    "    a = [i.split(\"==\")[0] for i in a]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56a6ac3e-74dd-43fe-8761-b44527d88ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "from tqdm import tqdm\n",
    "\n",
    "for i in tqdm(a):\n",
    "    bash_command = f\"pip3 uninstall {i} -y\"\n",
    "    process = subprocess.Popen(bash_command.split(), stdout=subprocess.PIPE)\n",
    "    output, error = process.communicate()\n",
    "\n",
    "    print(output)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf69bb3f-94e6-4dba-92cd-ce08df117d67",
   "metadata": {
    "id": "cf69bb3f-94e6-4dba-92cd-ce08df117d67"
   },
   "source": [
    "## EZKL Jupyter Notebook Demo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cb3e480f-c082-489c-a01c-0d4d431fe022",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_anal.ipynb  ezkl_antifraud.ipynb\n",
      "/home/sedan/ZeroEnter/antifraud\n"
     ]
    }
   ],
   "source": [
    "!ls\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e5769669-82a7-4968-b3da-8a8e24b85453",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a6e2ebc3-ae51-46c2-865c-622e65cd289d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NVIDIA RTX A6000\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "num_devices = torch.cuda.device_count()\n",
    "\n",
    "for i in range(num_devices):\n",
    "    print(torch.cuda.get_device_name(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3286851f-ba12-4451-94e5-f9bc614f8e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "from argparse import ArgumentParser, ArgumentDefaultsHelpFormatter\n",
    "\n",
    "def parse_args():\n",
    "    method = \"rgtan\"\n",
    "    yaml_file = \"config/rgtan_cfg.yaml\"\n",
    "\n",
    "    # config = Config().get_config()\n",
    "    with open(yaml_file) as file:\n",
    "        args = yaml.safe_load(file)\n",
    "    args['method'] = method\n",
    "    return args\n",
    "\n",
    "args = parse_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4abe677a-dc8d-4c49-9c34-f41145d75763",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'batch_size': 64,\n",
       " 'hid_dim': 256,\n",
       " 'lr': 0.003,\n",
       " 'wd': 0.0001,\n",
       " 'n_layers': 2,\n",
       " 'dropout': [0.2, 0.1],\n",
       " 'device': 'cuda:0',\n",
       " 'early_stopping': 10,\n",
       " 'n_fold': 5,\n",
       " 'seed': 2023,\n",
       " 'max_epochs': 15,\n",
       " 'gated': True,\n",
       " 'dataset': 'amazon',\n",
       " 'test_size': 0.6,\n",
       " 'nei_att_heads': {'yelp': 4, 'amazon': 5, 'S-FFSD': 9},\n",
       " 'method': 'rgtan'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "222be2ea-c9be-4742-b0aa-c7ea3b85e9c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from methods.rgtan.rgtan_main import rgtan_main, loda_rgtan_data\n",
    "\n",
    "# feat_data, labels, train_idx, test_idx, g, cat_features, neigh_features = loda_rgtan_data(args['dataset'], args['test_size'])\n",
    "\n",
    "\n",
    "# rgtan_main(feat_data, g, train_idx, test_idx, labels, args, cat_features, neigh_features, nei_att_head=args['nei_att_heads'][args['dataset']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "630cd0ee-81da-4717-b7bf-7347f0d0b6ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[01;34mconfig\u001b[0m/               LICENSE   \u001b[01;34mmodels\u001b[0m/     requirements.txt\n",
      "\u001b[01;34mdata\u001b[0m/                 main.py   \u001b[01;34mnotebooks\u001b[0m/  rm_clear.txt\n",
      "\u001b[01;34mfeature_engineering\u001b[0m/  \u001b[01;34mmethods\u001b[0m/  README.md   rm.txt\n"
     ]
    }
   ],
   "source": [
    "ls "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7a465464-a02f-4cca-9f8b-6daa36f03767",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6accffd0-b0db-407c-b9bc-980f2f42fcfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dgl.dataloading import MultiLayerFullNeighborSampler\n",
    "from dgl.dataloading import NodeDataLoader\n",
    "from torch.optim.lr_scheduler import MultiStepLR\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import dgl\n",
    "import pickle\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import average_precision_score, roc_auc_score, f1_score\n",
    "from scipy.io import loadmat\n",
    "from tqdm import tqdm\n",
    "# from . import *\n",
    "from methods.rgtan.rgtan_lpa import load_lpa_subtensor\n",
    "from methods.rgtan.rgtan_model import RGTAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "abb23ae6-27d1-4343-9b33-b916f9f62cbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no neighbohood feature used.\n"
     ]
    }
   ],
   "source": [
    "from methods.rgtan.rgtan_main import rgtan_main, loda_rgtan_data\n",
    "\n",
    "feat_data, labels, train_idx, test_idx, g, cat_features, neigh_features = loda_rgtan_data(\n",
    "    args['dataset'], args['test_size'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "339ea14f-97f1-471b-84a9-c1d5a9970012",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.autograd.set_detect_anomaly(True)\n",
    "device = args['device']\n",
    "graph = g.to(device)\n",
    "oof_predictions = torch.from_numpy(\n",
    "    np.zeros([len(feat_df), 2])).float().to(device)\n",
    "test_predictions = torch.from_numpy(\n",
    "    np.zeros([len(feat_df), 2])).float().to(device)\n",
    "kfold = StratifiedKFold(\n",
    "    n_splits=args['n_fold'], shuffle=True, random_state=args['seed'])\n",
    "\n",
    "y_target = labels.iloc[train_idx].values\n",
    "num_feat = torch.from_numpy(feat_df.values).float().to(device)\n",
    "cat_feat = {col: torch.from_numpy(feat_df[col].values).long().to(\n",
    "    device) for col in cat_features}\n",
    "\n",
    "neigh_padding_dict = {}\n",
    "nei_feat = []\n",
    "if isinstance(neigh_features, pd.DataFrame):  # otherwise []\n",
    "    # if null it is []\n",
    "    nei_feat = {col: torch.from_numpy(neigh_features[col].values).to(torch.float32).to(\n",
    "        device) for col in neigh_features.columns}\n",
    "\n",
    "y = labels\n",
    "labels = torch.from_numpy(y.values).long().to(device)\n",
    "loss_fn = nn.CrossEntropyLoss().to(device)\n",
    "for fold, (trn_idx, val_idx) in enumerate(kfold.split(feat_df.iloc[train_idx], y_target)):\n",
    "    print(f'Training fold {fold + 1}')\n",
    "    trn_ind, val_ind = torch.from_numpy(np.array(train_idx)[trn_idx]).long().to(\n",
    "        device), torch.from_numpy(np.array(train_idx)[val_idx]).long().to(device)\n",
    "\n",
    "    train_sampler = MultiLayerFullNeighborSampler(args['n_layers'])\n",
    "    train_dataloader = NodeDataLoader(graph,\n",
    "                                      trn_ind,\n",
    "                                      train_sampler,\n",
    "                                      device=device,\n",
    "                                      use_ddp=False,\n",
    "                                      batch_size=args['batch_size'],\n",
    "                                      shuffle=True,\n",
    "                                      drop_last=False,\n",
    "                                      num_workers=0\n",
    "                                      )\n",
    "    val_sampler = MultiLayerFullNeighborSampler(args['n_layers'])\n",
    "    val_dataloader = NodeDataLoader(graph,\n",
    "                                    val_ind,\n",
    "                                    val_sampler,\n",
    "                                    use_ddp=False,\n",
    "                                    device=device,\n",
    "                                    batch_size=args['batch_size'],\n",
    "                                    shuffle=True,\n",
    "                                    drop_last=False,\n",
    "                                    num_workers=0,\n",
    "                                    )\n",
    "#     model = RGTAN(in_feats=feat_df.shape[1],\n",
    "#                   hidden_dim=args['hid_dim']//4,\n",
    "#                   n_classes=2,\n",
    "#                   heads=[4]*args['n_layers'],\n",
    "#                   activation=nn.PReLU(),\n",
    "#                   n_layers=args['n_layers'],\n",
    "#                   drop=args['dropout'],\n",
    "#                   device=device,\n",
    "#                   gated=args['gated'],\n",
    "#                   ref_df=feat_df.iloc[train_idx],\n",
    "#                   cat_features=cat_feat,\n",
    "#                   neigh_features=nei_feat,\n",
    "#                   nei_att_head=nei_att_head).to(device)\n",
    "#     lr = args['lr'] * np.sqrt(args['batch_size']/1024)\n",
    "#     optimizer = optim.Adam(model.parameters(), lr=lr,\n",
    "#                            weight_decay=args['wd'])\n",
    "#     lr_scheduler = MultiStepLR(optimizer=optimizer, milestones=[\n",
    "#                                4000, 12000], gamma=0.3)\n",
    "\n",
    "#     earlystoper = early_stopper(\n",
    "#         patience=args['early_stopping'], verbose=True)\n",
    "#     start_epoch, max_epochs = 0, 2000\n",
    "#     for epoch in range(start_epoch, args['max_epochs']):\n",
    "#         train_loss_list = []\n",
    "#         # train_acc_list = []\n",
    "#         model.train()\n",
    "#         for step, (input_nodes, seeds, blocks) in enumerate(train_dataloader):\n",
    "#             # print(f\"loading batch data...\")\n",
    "#             batch_inputs, batch_work_inputs, batch_neighstat_inputs, batch_labels, lpa_labels = load_lpa_subtensor(num_feat, cat_feat, nei_feat, neigh_padding_dict, labels,\n",
    "#                                                                                                                    seeds, input_nodes, device, blocks)\n",
    "#             # print(f\"load {step}\")\n",
    "\n",
    "#             # batch_neighstat_inputs: {\"degree\":(|batch|, degree_dim)}\n",
    "\n",
    "#             blocks = [block.to(device) for block in blocks]\n",
    "#             train_batch_logits = model(\n",
    "#                 blocks, batch_inputs, lpa_labels, batch_work_inputs, batch_neighstat_inputs)\n",
    "#             mask = batch_labels == 2\n",
    "#             train_batch_logits = train_batch_logits[~mask]\n",
    "#             batch_labels = batch_labels[~mask]\n",
    "#             # batch_labels[mask] = 0\n",
    "\n",
    "#             train_loss = loss_fn(train_batch_logits, batch_labels)\n",
    "#             # backward\n",
    "#             optimizer.zero_grad()\n",
    "#             train_loss.backward()\n",
    "#             optimizer.step()\n",
    "#             lr_scheduler.step()\n",
    "#             train_loss_list.append(train_loss.cpu().detach().numpy())\n",
    "\n",
    "#             if step % 10 == 0:\n",
    "#                 tr_batch_pred = torch.sum(torch.argmax(train_batch_logits.clone(\n",
    "#                 ).detach(), dim=1) == batch_labels) / batch_labels.shape[0]\n",
    "#                 score = torch.softmax(train_batch_logits.clone().detach(), dim=1)[\n",
    "#                     :, 1].cpu().numpy()\n",
    "#                 try:\n",
    "#                     print('In epoch:{:03d}|batch:{:04d}, train_loss:{:4f}, '\n",
    "#                           'train_ap:{:.4f}, train_acc:{:.4f}, train_auc:{:.4f}'.format(epoch, step,\n",
    "#                                                                                        np.mean(\n",
    "#                                                                                            train_loss_list),\n",
    "#                                                                                        average_precision_score(\n",
    "#                                                                                            batch_labels.cpu().numpy(), score),\n",
    "#                                                                                        tr_batch_pred.detach(),\n",
    "#                                                                                        roc_auc_score(batch_labels.cpu().numpy(), score)))\n",
    "#                 except:\n",
    "#                     pass\n",
    "\n",
    "#         # mini-batch for validation\n",
    "#         val_loss_list = 0\n",
    "#         val_acc_list = 0\n",
    "#         val_all_list = 0\n",
    "#         model.eval()\n",
    "#         with torch.no_grad():\n",
    "#             for step, (input_nodes, seeds, blocks) in enumerate(val_dataloader):\n",
    "#                 batch_inputs, batch_work_inputs, batch_neighstat_inputs, batch_labels, lpa_labels = load_lpa_subtensor(num_feat, cat_feat, nei_feat, neigh_padding_dict, labels,\n",
    "#                                                                                                                        seeds, input_nodes, device, blocks)\n",
    "\n",
    "#                 blocks = [block.to(device) for block in blocks]\n",
    "#                 val_batch_logits = model(\n",
    "#                     blocks, batch_inputs, lpa_labels, batch_work_inputs, batch_neighstat_inputs)\n",
    "#                 oof_predictions[seeds] = val_batch_logits\n",
    "#                 mask = batch_labels == 2\n",
    "#                 val_batch_logits = val_batch_logits[~mask]\n",
    "#                 batch_labels = batch_labels[~mask]\n",
    "#                 # batch_labels[mask] = 0\n",
    "#                 val_loss_list = val_loss_list + \\\n",
    "#                     loss_fn(val_batch_logits, batch_labels)\n",
    "#                 # val_all_list += 1\n",
    "#                 val_batch_pred = torch.sum(torch.argmax(\n",
    "#                     val_batch_logits, dim=1) == batch_labels) / torch.tensor(batch_labels.shape[0])\n",
    "#                 val_acc_list = val_acc_list + val_batch_pred * \\\n",
    "#                     torch.tensor(\n",
    "#                         batch_labels.shape[0])  # how many in this batch is right!\n",
    "#                 val_all_list = val_all_list + \\\n",
    "#                     batch_labels.shape[0]  # how many val nodes\n",
    "#                 if step % 10 == 0:\n",
    "#                     score = torch.softmax(val_batch_logits.clone().detach(), dim=1)[\n",
    "#                         :, 1].cpu().numpy()\n",
    "#                     try:\n",
    "#                         print('In epoch:{:03d}|batch:{:04d}, val_loss:{:4f}, val_ap:{:.4f}, '\n",
    "#                               'val_acc:{:.4f}, val_auc:{:.4f}'.format(epoch,\n",
    "#                                                                       step,\n",
    "#                                                                       val_loss_list/val_all_list,\n",
    "#                                                                       average_precision_score(\n",
    "#                                                                           batch_labels.cpu().numpy(), score),\n",
    "#                                                                       val_batch_pred.detach(),\n",
    "#                                                                       roc_auc_score(batch_labels.cpu().numpy(), score)))\n",
    "#                     except:\n",
    "#                         pass\n",
    "\n",
    "#         # val_acc_list/val_all_list, model)\n",
    "#         earlystoper.earlystop(val_loss_list/val_all_list, model)\n",
    "#         if earlystoper.is_earlystop:\n",
    "#             print(\"Early Stopping!\")\n",
    "#             break\n",
    "#     print(\"Best val_loss is: {:.7f}\".format(earlystoper.best_cv))\n",
    "#     test_ind = torch.from_numpy(np.array(test_idx)).long().to(device)\n",
    "#     test_sampler = MultiLayerFullNeighborSampler(args['n_layers'])\n",
    "#     test_dataloader = NodeDataLoader(graph,\n",
    "#                                      test_ind,\n",
    "#                                      test_sampler,\n",
    "#                                      use_ddp=False,\n",
    "#                                      device=device,\n",
    "#                                      batch_size=args['batch_size'],\n",
    "#                                      shuffle=True,\n",
    "#                                      drop_last=False,\n",
    "#                                      num_workers=0,\n",
    "#                                      )\n",
    "#     b_model = earlystoper.best_model.to(device)\n",
    "#     b_model.eval()\n",
    "#     with torch.no_grad():\n",
    "#         for step, (input_nodes, seeds, blocks) in enumerate(test_dataloader):\n",
    "#             # print(input_nodes)\n",
    "#             batch_inputs, batch_work_inputs, batch_neighstat_inputs, batch_labels, lpa_labels = load_lpa_subtensor(num_feat, cat_feat, nei_feat, neigh_padding_dict, labels,\n",
    "#                                                                                                                    seeds, input_nodes, device, blocks)\n",
    "\n",
    "#             blocks = [block.to(device) for block in blocks]\n",
    "#             test_batch_logits = b_model(\n",
    "#                 blocks, batch_inputs, lpa_labels, batch_work_inputs, batch_neighstat_inputs)\n",
    "#             test_predictions[seeds] = test_batch_logits\n",
    "#             test_batch_pred = torch.sum(torch.argmax(\n",
    "#                 test_batch_logits, dim=1) == batch_labels) / torch.tensor(batch_labels.shape[0])\n",
    "#             if step % 10 == 0:\n",
    "#                 print('In test batch:{:04d}'.format(step))\n",
    "# mask = y_target == 2\n",
    "# y_target[mask] = 0\n",
    "# my_ap = average_precision_score(y_target, torch.softmax(\n",
    "#     oof_predictions, dim=1).cpu()[train_idx, 1])\n",
    "\n",
    "\n",
    "# print(\"NN out of fold AP is:\", my_ap)\n",
    "# b_models, val_gnn_0, test_gnn_0 = earlystoper.best_model.to(\n",
    "#     'cpu'), oof_predictions, test_predictions\n",
    "\n",
    "# test_score = torch.softmax(test_gnn_0, dim=1)[test_idx, 1].cpu().numpy()\n",
    "# y_target = labels[test_idx].cpu().numpy()\n",
    "# test_score1 = torch.argmax(test_gnn_0, dim=1)[test_idx].cpu().numpy()\n",
    "\n",
    "# mask = y_target != 2\n",
    "# test_score = test_score[mask]\n",
    "# y_target = y_target[mask]\n",
    "# test_score1 = test_score1[mask]\n",
    "\n",
    "# print(\"test AUC:\", roc_auc_score(y_target, test_score))\n",
    "# print(\"test f1:\", f1_score(y_target, test_score1, average=\"macro\"))\n",
    "# print(\"test AP:\", average_precision_score(y_target, test_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95613ee9",
   "metadata": {
    "id": "95613ee9"
   },
   "outputs": [],
   "source": [
    "# check if notebook is in colab\n",
    "try:\n",
    "    # install ezkl\n",
    "    import google.colab\n",
    "    import subprocess\n",
    "    import sys\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"ezkl\"])\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"onnx\"])\n",
    "\n",
    "# rely on local installation of ezkl if the notebook is not in colab\n",
    "except:\n",
    "    pass\n",
    "\n",
    "\n",
    "# here we create and (potentially train a model)\n",
    "\n",
    "# make sure you have the dependencies required here already installed\n",
    "from torch import nn\n",
    "import ezkl\n",
    "import os\n",
    "import json\n",
    "import torch\n",
    "\n",
    "\n",
    "# Defines the model\n",
    "# we got convs, we got relu, we got linear layers\n",
    "# What else could one want ????\n",
    "\n",
    "class MyModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyModel, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=2, kernel_size=5, stride=2)\n",
    "        self.conv2 = nn.Conv2d(in_channels=2, out_channels=3, kernel_size=5, stride=2)\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        self.d1 = nn.Linear(48, 48)\n",
    "        self.d2 = nn.Linear(48, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 32x1x28x28 => 32x32x26x26\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.relu(x)\n",
    "\n",
    "        # flatten => 32 x (32*26*26)\n",
    "        x = x.flatten(start_dim = 1)\n",
    "\n",
    "        # 32 x (32*26*26) => 32x128\n",
    "        x = self.d1(x)\n",
    "        x = self.relu(x)\n",
    "\n",
    "        # logits => 32x10\n",
    "        logits = self.d2(x)\n",
    "\n",
    "        return logits\n",
    "\n",
    "\n",
    "circuit = MyModel()\n",
    "\n",
    "# Train the model as you like here (skipped for brevity)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b37637c4",
   "metadata": {
    "id": "b37637c4"
   },
   "outputs": [],
   "source": [
    "model_path = os.path.join('network.onnx')\n",
    "compiled_model_path = os.path.join('network.compiled')\n",
    "pk_path = os.path.join('test.pk')\n",
    "vk_path = os.path.join('test.vk')\n",
    "settings_path = os.path.join('settings.json')\n",
    "srs_path = os.path.join('kzg.srs')\n",
    "witness_path = os.path.join('witness.json')\n",
    "data_path = os.path.join('input.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82db373a",
   "metadata": {
    "id": "82db373a"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# After training, export to onnx (network.onnx) and create a data file (input.json)\n",
    "x = 0.1*torch.rand(1,*[1, 28, 28], requires_grad=True)\n",
    "\n",
    "# Flips the neural net into inference mode\n",
    "circuit.eval()\n",
    "\n",
    "    # Export the model\n",
    "torch.onnx.export(circuit,               # model being run\n",
    "                  x,                   # model input (or a tuple for multiple inputs)\n",
    "                  model_path,            # where to save the model (can be a file or file-like object)\n",
    "                  export_params=True,        # store the trained parameter weights inside the model file\n",
    "                  opset_version=10,          # the ONNX version to export the model to\n",
    "                  do_constant_folding=True,  # whether to execute constant folding for optimization\n",
    "                  input_names = ['input'],   # the model's input names\n",
    "                  output_names = ['output'], # the model's output names\n",
    "                  dynamic_axes={'input' : {0 : 'batch_size'},    # variable length axes\n",
    "                                'output' : {0 : 'batch_size'}})\n",
    "\n",
    "data_array = ((x).detach().numpy()).reshape([-1]).tolist()\n",
    "\n",
    "data = dict(input_data = [data_array])\n",
    "\n",
    "    # Serialize data into file:\n",
    "json.dump( data, open(data_path, 'w' ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5e374a2",
   "metadata": {
    "id": "d5e374a2"
   },
   "outputs": [],
   "source": [
    "!RUST_LOG=trace\n",
    "# TODO: Dictionary outputs\n",
    "res = ezkl.gen_settings(model_path, settings_path)\n",
    "assert res == True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aa4f090",
   "metadata": {
    "id": "3aa4f090"
   },
   "outputs": [],
   "source": [
    "res = ezkl.compile_model(model_path, compiled_model_path, settings_path)\n",
    "assert res == True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b74dcee",
   "metadata": {
    "id": "8b74dcee"
   },
   "outputs": [],
   "source": [
    "# srs path\n",
    "res = ezkl.get_srs(srs_path, settings_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18c8b7c7",
   "metadata": {
    "id": "18c8b7c7"
   },
   "outputs": [],
   "source": [
    "# now generate the witness file\n",
    "\n",
    "res = ezkl.gen_witness(data_path, compiled_model_path, witness_path, settings_path = settings_path)\n",
    "assert os.path.isfile(witness_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1c561a8",
   "metadata": {
    "id": "b1c561a8"
   },
   "outputs": [],
   "source": [
    "\n",
    "# HERE WE SETUP THE CIRCUIT PARAMS\n",
    "# WE GOT KEYS\n",
    "# WE GOT CIRCUIT PARAMETERS\n",
    "# EVERYTHING ANYONE HAS EVER NEEDED FOR ZK\n",
    "\n",
    "\n",
    "\n",
    "res = ezkl.setup(\n",
    "        compiled_model_path,\n",
    "        vk_path,\n",
    "        pk_path,\n",
    "        srs_path,\n",
    "        settings_path,\n",
    "    )\n",
    "\n",
    "assert res == True\n",
    "assert os.path.isfile(vk_path)\n",
    "assert os.path.isfile(pk_path)\n",
    "assert os.path.isfile(settings_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c384cbc8",
   "metadata": {
    "id": "c384cbc8"
   },
   "outputs": [],
   "source": [
    "# GENERATE A PROOF\n",
    "\n",
    "\n",
    "proof_path = os.path.join('test.pf')\n",
    "\n",
    "res = ezkl.prove(\n",
    "        witness_path,\n",
    "        compiled_model_path,\n",
    "        pk_path,\n",
    "        proof_path,\n",
    "        srs_path,\n",
    "        \"evm\",\n",
    "        \"single\",\n",
    "        settings_path,\n",
    "    )\n",
    "\n",
    "print(res)\n",
    "assert os.path.isfile(proof_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76f00d41",
   "metadata": {
    "id": "76f00d41"
   },
   "outputs": [],
   "source": [
    "# VERIFY IT\n",
    "\n",
    "res = ezkl.verify(\n",
    "        proof_path,\n",
    "        settings_path,\n",
    "        vk_path,\n",
    "        srs_path,\n",
    "    )\n",
    "\n",
    "assert res == True\n",
    "print(\"verified\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
